{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Transition Simulation\n",
    "\n",
    "This notebook demonstrates the sharp phase transition in RLVR governed by Youden's index:\n",
    "\n",
    "$$J = \\text{TPR} - \\text{FPR} = (1 - \\text{FN}) - \\text{FP}$$\n",
    "\n",
    "- **J > 0**: Learning proceeds, bad modes decay\n",
    "- **J = 0**: Neutral drift, no learning\n",
    "- **J < 0**: Anti-learning, model collapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, replace\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 12, 'figure.figsize': (10, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    T: float = 500.0      # Total time\n",
    "    dt: float = 1.0       # Time step\n",
    "    eta: float = 0.01     # Learning rate\n",
    "    p0: float = 0.5       # Initial bad mode probability\n",
    "    FP: float = 0.0       # False positive rate\n",
    "    FN: float = 0.0       # False negative rate\n",
    "    n_runs: int = 10      # Ensemble size\n",
    "    seed: int = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Dynamics\n",
    "\n",
    "The mean-field ODE for the bad mode probability $p(t)$:\n",
    "\n",
    "$$\\frac{dp}{dt} = -\\eta \\cdot \\frac{J}{\\sigma} \\cdot [p(1-p)]^2$$\n",
    "\n",
    "where $\\sigma = \\sqrt{q(1-q)}$ and $q = (1 - \\text{FN}) - J \\cdot p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_J(FP, FN):\n",
    "    \"\"\"Compute Youden's index.\"\"\"\n",
    "    return 1 - FN - FP\n",
    "\n",
    "def step_p(p, eta, FP, FN, dt):\n",
    "    \"\"\"One step of the mean-field ODE.\"\"\"\n",
    "    J = compute_J(FP, FN)\n",
    "    q = (1 - FN) - J * p\n",
    "    sigma = np.sqrt(np.clip(q * (1 - q), 1e-12, None))\n",
    "    dp = -eta * (J / sigma) * (p * (1 - p))**2\n",
    "    return np.clip(p + dp * dt, 1e-9, 1 - 1e-9)\n",
    "\n",
    "def simulate(cfg: Config):\n",
    "    \"\"\"Simulate the dynamics.\"\"\"\n",
    "    steps = int(cfg.T / cfg.dt)\n",
    "    t = np.linspace(0, cfg.T, steps + 1)\n",
    "    p = np.empty(steps + 1)\n",
    "    p[0] = cfg.p0\n",
    "    \n",
    "    for k in range(steps):\n",
    "        p[k+1] = step_p(p[k], cfg.eta, cfg.FP, cfg.FN, cfg.dt)\n",
    "    \n",
    "    return t, p, 1 - p  # t, bad_prob, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Different Noise Regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Config()\n",
    "\n",
    "scenarios = [\n",
    "    (\"J = 1.0 (Clean)\", replace(base, FP=0.0, FN=0.0)),\n",
    "    (\"J = 0.6 (Moderate noise)\", replace(base, FP=0.2, FN=0.2)),\n",
    "    (\"J = 0.2 (High noise)\", replace(base, FP=0.4, FN=0.4)),\n",
    "    (\"J = 0.0 (Critical)\", replace(base, FP=0.5, FN=0.5)),\n",
    "    (\"J = -0.2 (Anti-learning)\", replace(base, FP=0.6, FN=0.6)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, cfg in scenarios:\n",
    "    t, p, acc = simulate(cfg)\n",
    "    J = compute_J(cfg.FP, cfg.FN)\n",
    "    results.append((name, J, t, p, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Phase Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "cmap = plt.cm.RdYlBu\n",
    "\n",
    "for name, J, t, p, acc in results:\n",
    "    color = cmap((J + 0.3) / 1.3)  # Map J to color\n",
    "    axes[0].plot(t, p, label=f'{name}', color=color, linewidth=2)\n",
    "    axes[1].plot(t, acc * 100, label=f'{name}', color=color, linewidth=2)\n",
    "\n",
    "axes[0].set_xlabel('Step t')\n",
    "axes[0].set_ylabel('Bad mode probability p(t)')\n",
    "axes[0].set_title('Bad Mode Decay')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "axes[1].set_xlabel('Step t')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Learning Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "plt.suptitle('Phase Transition: Rate vs Fate', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insight\n",
    "\n",
    "When **J > 0**, the bad mode probability $p(t) \\to 0$ as $t \\to \\infty$. The noise only affects the *rate* of convergence.\n",
    "\n",
    "When **J = 0**, there's no net learning signal - the model drifts randomly.\n",
    "\n",
    "When **J < 0**, the dynamics reverse - the model *anti-learns* and collapses to bad modes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
