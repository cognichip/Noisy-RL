{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Dynamics: Wright-Fisher Diffusion\n",
    "\n",
    "This notebook demonstrates the stochastic dynamics of mode competition in RLVR.\n",
    "\n",
    "Within the good modes, competition follows Wright-Fisher diffusion - a classical model from population genetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 12, 'figure.figsize': (12, 5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wright-Fisher Diffusion on the Simplex\n",
    "\n",
    "For K modes with shares $y = (y_1, ..., y_K)$ on the simplex, the SDE is:\n",
    "\n",
    "$$dy_i = \\lambda (u_i - y_i) dt + \\sqrt{V} \\left( \\sqrt{y_i} dB_i - y_i \\sum_k \\sqrt{y_k} dB_k \\right)$$\n",
    "\n",
    "where:\n",
    "- $\\lambda$ is the KL regularization strength\n",
    "- $u$ is the reference distribution\n",
    "- $V$ is the noise intensity (related to batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_wf(y0, lam, V, T, dt, seed=42):\n",
    "    \"\"\"\n",
    "    Simulate Wright-Fisher diffusion with diversity drift.\n",
    "    \n",
    "    Args:\n",
    "        y0: Initial distribution (K-dim, sums to 1)\n",
    "        lam: KL regularization strength\n",
    "        V: Noise intensity\n",
    "        T: Total time\n",
    "        dt: Time step\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    K = len(y0)\n",
    "    u = np.ones(K) / K  # Uniform reference\n",
    "    \n",
    "    n_steps = int(T / dt)\n",
    "    t = np.linspace(0, T, n_steps + 1)\n",
    "    Y = np.zeros((n_steps + 1, K))\n",
    "    Y[0] = y0\n",
    "    \n",
    "    sqrt_V_dt = np.sqrt(V * dt)\n",
    "    \n",
    "    for k in range(n_steps):\n",
    "        y = np.maximum(Y[k], 1e-10)\n",
    "        y = y / y.sum()\n",
    "        \n",
    "        # Drift (KL regularization towards uniform)\n",
    "        drift = lam * (u - y) * dt\n",
    "        \n",
    "        # Noise (Wright-Fisher)\n",
    "        z = rng.normal(size=K)\n",
    "        sqrt_y = np.sqrt(y)\n",
    "        proj = np.dot(sqrt_y, z)\n",
    "        noise = sqrt_V_dt * (sqrt_y * z - y * proj)\n",
    "        \n",
    "        y_next = y + drift + noise\n",
    "        y_next = np.maximum(y_next, 0)\n",
    "        y_next = y_next / y_next.sum()\n",
    "        Y[k + 1] = y_next\n",
    "    \n",
    "    return t, Y\n",
    "\n",
    "def entropy(y):\n",
    "    \"\"\"Shannon entropy of distribution y.\"\"\"\n",
    "    y = np.clip(y, 1e-12, 1)\n",
    "    return -np.sum(y * np.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of KL Regularization\n",
    "\n",
    "Without KL regularization ($\\lambda = 0$), the system eventually fixates on one mode (entropy drops).\n",
    "\n",
    "With KL regularization ($\\lambda > 0$), diversity is maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "y0 = np.ones(K) / K  # Start uniform\n",
    "V = 0.3\n",
    "T = 10.0\n",
    "dt = 0.01\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Case 1: No KL regularization\n",
    "t1, Y1 = simulate_wf(y0, lam=0.0, V=V, T=T, dt=dt, seed=42)\n",
    "\n",
    "# Case 2: With KL regularization  \n",
    "t2, Y2 = simulate_wf(y0, lam=1.0, V=V, T=T, dt=dt, seed=42)\n",
    "\n",
    "# Plot mode shares\n",
    "for i in range(K):\n",
    "    axes[0, 0].plot(t1, Y1[:, i], label=f'Mode {i+1}')\n",
    "    axes[0, 1].plot(t2, Y2[:, i], label=f'Mode {i+1}')\n",
    "\n",
    "axes[0, 0].set_title('No KL Regularization ($\\\\lambda = 0$)', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Mode share')\n",
    "axes[0, 0].legend(loc='upper right')\n",
    "\n",
    "axes[0, 1].set_title('With KL Regularization ($\\\\lambda = 1$)', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Time')\n",
    "axes[0, 1].set_ylabel('Mode share')\n",
    "axes[0, 1].legend(loc='upper right')\n",
    "\n",
    "# Plot entropy\n",
    "H1 = [entropy(Y1[k]) for k in range(len(t1))]\n",
    "H2 = [entropy(Y2[k]) for k in range(len(t2))]\n",
    "H_max = np.log(K)\n",
    "\n",
    "axes[1, 0].plot(t1, H1, 'b-', linewidth=2)\n",
    "axes[1, 0].axhline(H_max, color='gray', linestyle='--', label=f'Max entropy (ln {K})')\n",
    "axes[1, 0].set_title('Entropy Over Time ($\\\\lambda = 0$)', fontsize=12)\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Entropy H(y)')\n",
    "axes[1, 0].set_ylim(0, H_max * 1.1)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].plot(t2, H2, 'b-', linewidth=2)\n",
    "axes[1, 1].axhline(H_max, color='gray', linestyle='--', label=f'Max entropy (ln {K})')\n",
    "axes[1, 1].set_title('Entropy Over Time ($\\\\lambda = 1$)', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "axes[1, 1].set_ylabel('Entropy H(y)')\n",
    "axes[1, 1].set_ylim(0, H_max * 1.1)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.suptitle('Wright-Fisher Diffusion: Mode Competition', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo: Entropy Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc = 50\n",
    "T_long = 20.0\n",
    "\n",
    "H_no_kl = []\n",
    "H_with_kl = []\n",
    "\n",
    "for seed in range(n_mc):\n",
    "    _, Y = simulate_wf(y0, lam=0.0, V=V, T=T_long, dt=dt, seed=seed)\n",
    "    H_no_kl.append([entropy(Y[k]) for k in range(len(Y))])\n",
    "    \n",
    "    _, Y = simulate_wf(y0, lam=1.0, V=V, T=T_long, dt=dt, seed=seed)\n",
    "    H_with_kl.append([entropy(Y[k]) for k in range(len(Y))])\n",
    "\n",
    "H_no_kl = np.array(H_no_kl)\n",
    "H_with_kl = np.array(H_with_kl)\n",
    "t_long = np.linspace(0, T_long, H_no_kl.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot mean and confidence band\n",
    "ax.plot(t_long, H_no_kl.mean(axis=0), 'r-', label='$\\\\lambda = 0$ (no KL)', linewidth=2)\n",
    "ax.fill_between(t_long, \n",
    "                np.percentile(H_no_kl, 10, axis=0),\n",
    "                np.percentile(H_no_kl, 90, axis=0), \n",
    "                color='red', alpha=0.2)\n",
    "\n",
    "ax.plot(t_long, H_with_kl.mean(axis=0), 'b-', label='$\\\\lambda = 1$ (with KL)', linewidth=2)\n",
    "ax.fill_between(t_long,\n",
    "                np.percentile(H_with_kl, 10, axis=0),\n",
    "                np.percentile(H_with_kl, 90, axis=0),\n",
    "                color='blue', alpha=0.2)\n",
    "\n",
    "ax.axhline(H_max, color='gray', linestyle='--', label='Max entropy')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Entropy H(y)')\n",
    "ax.set_title('Monte Carlo: Entropy Dynamics (mean $\\\\pm$ 80% CI)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, H_max * 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "- **Without KL regularization**: Stochastic sampling noise causes modes to compete until one dominates (entropy collapse)\n",
    "- **With KL regularization**: The system maintains diversity near the reference distribution\n",
    "\n",
    "This is why KL regularization in RLHF/GRPO helps maintain response diversity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
